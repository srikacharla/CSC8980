{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZmpAF/tMm+YFqIomeb6nA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srikacharla/CSC8980/blob/main/Homework4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xUPdMRuL1ii"
      },
      "source": [
        "Name: Sri Harsha Kacharla\n",
        "Student ID: 002556509"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRI9PBoXL0qq"
      },
      "source": [
        "1.Take the positive and the negative tweets only. Use Sklearn to split the dataset in 80%\n",
        "training, 20% testing splits. Provide a nicely formatted summary of these splits,\n",
        "containing their size) (15 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmMAA1cwL8uy",
        "outputId": "3681503c-0748-4f44-d5f0-5b43a7fd7c2d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lEI5jdDMMJw",
        "outputId": "309b8fa8-f26a-417e-ff33-cafe1dcf308a"
      },
      "source": [
        "!mkdir -p data\n",
        "!wget -nc http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip -P data\n",
        "!unzip /content/data/trainingandtestdata.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "URL transformed to HTTPS due to an HSTS policy\n",
            "File ‘data/trainingandtestdata.zip’ already there; not retrieving.\n",
            "\n",
            "Archive:  /content/data/trainingandtestdata.zip\n",
            "replace testdata.manual.2009.06.14.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3-sw1LUMv0M"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "training_data = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin-1', names=['polarity', 'id', 'date', 'query', 'name', 'text'])\n",
        "testing_data = pd.read_csv('testdata.manual.2009.06.14.csv', names=['polarity', 'id', 'date', 'query', 'name', 'text'])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYdTE4d4NBsX"
      },
      "source": [
        "training_data.query('polarity == \"0\" or polarity == \"4\"')\n",
        "np.random.seed(2361)\n",
        "x_train, x_test, y_train, y_test = train_test_split(training_data.drop('polarity', axis='columns'), training_data.polarity,train_size=0.80)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQJ8rC1GNE0I"
      },
      "source": [
        "y_train = y_train.to_frame()\n",
        "y_test = y_test.to_frame()\n",
        "split_size = [x_train.size, x_test.size, y_train.size, y_test.size]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "D3Slafv9NG8g",
        "outputId": "618792bf-c02c-42ef-82b7-90266c65e9e6"
      },
      "source": [
        "df = pd.DataFrame({'size of data':split_size}, index = ['x training dataset size', 'x testing dataset size', 'y training dataset size', 'y testing dataset size'])\n",
        "df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>size of data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>x training dataset size</th>\n",
              "      <td>6400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x testing dataset size</th>\n",
              "      <td>1600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y training dataset size</th>\n",
              "      <td>1280000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y testing dataset size</th>\n",
              "      <td>320000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         size of data\n",
              "x training dataset size       6400000\n",
              "x testing dataset size        1600000\n",
              "y training dataset size       1280000\n",
              "y testing dataset size         320000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_g44Q3xNNUG"
      },
      "source": [
        "2. Use the code from the previous classes to build the following models (15 points):\n",
        "\n",
        "  a) SVM using TF-IDF.\n",
        "\n",
        "  b) Naive Bayes using TF-IDF.\n",
        "\n",
        "  c) Random Forest using TF-IDF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioK_3cZcNStb"
      },
      "source": [
        "import sklearn\n",
        "np.random.seed(2361)\n",
        "model_nb = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "model_nb.fit(x_train.text.values.ravel(), y_train.values.ravel())\n",
        "labels2 = model_nb.predict(x_test.text.values)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSKWu9URNqP5"
      },
      "source": [
        "np.random.seed(2361)\n",
        "y_train_values = y_train.values.ravel()\n",
        "y_train_values = y_train_values.astype(np.int8)\n",
        "model_rf = make_pipeline(TfidfVectorizer(), RandomForestClassifier(n_jobs=-1,warm_start=True,max_depth=1000))\n",
        "model_rf.fit(x_train.text.values.ravel(), y_train_values)\n",
        "labels3 = model_rf.predict(x_test.text.values)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkZyNhJARJ9W",
        "outputId": "177a56f8-0f1b-4154-89b5-6b84678a081c"
      },
      "source": [
        "np.random.seed(2361)\n",
        "model_svm = make_pipeline(TfidfVectorizer(), SVC(max_iter=20000))\n",
        "model_svm.fit(x_train.text.values.ravel(), y_train_values)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=20000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidfvectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('svc',\n",
              "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                     gamma='scale', kernel='rbf', max_iter=20000,\n",
              "                     probability=False, random_state=None, shrinking=True,\n",
              "                     tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLba2GezRjCX"
      },
      "source": [
        "3. Use the code from the LSTM class to build a classifier for negative and positive\n",
        "sentiment tweets. Train the model with the training data split. Once the model is built,\n",
        "test it with the testing data split. Display the classifier report for this evaluation. Answer\n",
        "the following question: What can you say about the performance of this model? (40\n",
        "points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzeZsdopSysi"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=280)\n",
        "tokenizer.fit_on_texts(training_data.text.values) \n",
        "sequences_train = tokenizer.texts_to_sequences(x_train.text.values)\n",
        "sequences_test = tokenizer.texts_to_sequences(x_test.text.values)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPjJCAh1Rlm5",
        "outputId": "b60cb9f8-a5a0-4e5b-82fe-4f1104c107f9"
      },
      "source": [
        "!pip install numpy==1.16.2\n",
        "\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from numpy import array\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "review_length = 280\n",
        "vocab_size = 10000\n",
        "x1_train = sequence.pad_sequences(sequences_train, maxlen = review_length)\n",
        "x1_test = sequence.pad_sequences(sequences_test, maxlen = review_length)\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim = vocab_size, \n",
        "        output_dim = 32, \n",
        "        input_length = review_length \n",
        "    )\n",
        ")\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 \n",
        "    )\n",
        ")\n",
        "model.add(\n",
        "    tf.keras.layers.LSTM(\n",
        "        units=32 \n",
        "    )\n",
        ")\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 \n",
        "    )\n",
        ")\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1,\n",
        "        activation='sigmoid'\n",
        "    )\n",
        ")\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy, \n",
        "    optimizer=tf.keras.optimizers.Adam(), \n",
        "    metrics=['accuracy']) \n",
        "model.summary()\n",
        "y_train1 = y_train\n",
        "y_test1 = y_test\n",
        "y_train1 = y_train1.replace(4,1)\n",
        "y_test1 = y_test1.replace(4,1)\n",
        "history = model.fit(x1_train, y_train1,batch_size=256,epochs=3,validation_split=0.2,verbose=1)\n",
        "\n",
        "predicted_classes = model.predict_classes(x1_test)\n",
        "print(predicted_classes)\n",
        "classification_report = classification_report(y_test1, predicted_classes)\n",
        "print(classification_report)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.16.2 in /usr/local/lib/python3.7/dist-packages (1.16.2)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 280, 32)           320000    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 280, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 328,353\n",
            "Trainable params: 328,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "125/125 [==============================] - 7s 29ms/step - loss: 0.6739 - accuracy: 0.5791 - val_loss: 0.5680 - val_accuracy: 0.7080\n",
            "Epoch 2/3\n",
            "125/125 [==============================] - 3s 21ms/step - loss: 0.5709 - accuracy: 0.7080 - val_loss: 0.5471 - val_accuracy: 0.7200\n",
            "Epoch 3/3\n",
            "125/125 [==============================] - 3s 21ms/step - loss: 0.5591 - accuracy: 0.7142 - val_loss: 0.5452 - val_accuracy: 0.7251\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [0]\n",
            " [1]\n",
            " [1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.73      0.73      4995\n",
            "           1       0.73      0.72      0.73      5005\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.73      0.73      0.73     10000\n",
            "weighted avg       0.73      0.73      0.73     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGc4bzFz6zTo"
      },
      "source": [
        "The performance of this model is comparable to the SVC, Naive Bayes and Random Forest. Although it does slightly poor compared to the other models if we look at the precision scores. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfLDsCsBjB_F"
      },
      "source": [
        "4. Compare all models together in terms of Precision, Recall and F1 score. Put all of\n",
        "these numbers in a nicely formatted dataframe. Answer the following questions: Which\n",
        "model performs the best? Why do you think this is? What do you think you can do to\n",
        "improve performance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBfp_3M7jFa3",
        "outputId": "b76752fb-dbc1-42fc-965b-5b26b8832c52"
      },
      "source": [
        "import sklearn\n",
        "\n",
        "Precision = []\n",
        "Recall = []\n",
        "F1Score = []\n",
        "\n",
        "labels_nb = model_nb.predict(x_test.text.values)\n",
        "\n",
        "Precision.append(sklearn.metrics.precision_score(y_test.values,labels_nb,pos_label=4))\n",
        "Recall.append(sklearn.metrics.recall_score(y_test,labels_nb,pos_label=4))\n",
        "F1Score.append( sklearn.metrics.f1_score(y_test,labels_nb, average='macro',pos_label=4))\n",
        "\n",
        "\n",
        "labels_rf = model_rf.predict(x_test.text.values)\n",
        "Precision.append(sklearn.metrics.precision_score(y_test,labels_rf,pos_label=4))\n",
        "Recall.append(sklearn.metrics.recall_score(y_test,labels_rf,pos_label=4))\n",
        "F1Score.append( sklearn.metrics.f1_score(y_test,labels_rf, average='macro',pos_label=4))\n",
        "\n",
        "\n",
        "\n",
        "labels_svm = model_svm.predict(x_test.text.values)\n",
        "Precision.append(sklearn.metrics.precision_score(y_test,labels_svm,pos_label=4))\n",
        "Recall.append(sklearn.metrics.recall_score(y_test,labels_svm,pos_label=4))\n",
        "F1Score.append(sklearn.metrics.f1_score(y_test,labels_svm, average='macro',pos_label=4))\n",
        "\n",
        "\n",
        "Precision.append(sklearn.metrics.precision_score(y_test1,predicted_classes,pos_label=1))\n",
        "Recall.append(sklearn.metrics.recall_score(y_test1,predicted_classes,pos_label=1))\n",
        "F1Score.append(sklearn.metrics.f1_score(y_test1,predicted_classes, average='macro',pos_label=1))\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 4) is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 4) is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 4) is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfeoqMhtwVDM",
        "outputId": "32c8758e-0564-454a-cb6e-70f9886e135f"
      },
      "source": [
        "print(\"Bayes\")\n",
        "\n",
        "print('Precision:', Precision[0])\n",
        "print('Recall:', Recall[0])\n",
        "print('F1 Score:',F1Score[0])\n",
        "\n",
        "print(\"\\nRandom Forest\")\n",
        "\n",
        "print('Precision:',Precision[1] )\n",
        "print('Recall:',Recall[1] )\n",
        "print('F1 Score:',F1Score[1] )\n",
        "\n",
        "print(\"\\nSVM\")\n",
        "\n",
        "print('Precision:',Precision[2] )\n",
        "print('Recall:',Recall[2] )\n",
        "print('F1 Score:',F1Score[2] )\n",
        "\n",
        "print(\"\\nLSTM\")\n",
        "\n",
        "print('Precision:',Precision[3] )\n",
        "print('Recall:',Recall[3] )\n",
        "print('F1 Score:',F1Score[3] )\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bayes\n",
            "Precision: 0.7883574007220217\n",
            "Recall: 0.6981018981018982\n",
            "F1 Score: 0.7543212746008896\n",
            "\n",
            "Random Forest\n",
            "Precision: 0.7683686176836861\n",
            "Recall: 0.7396603396603396\n",
            "F1 Score: 0.7580241913989234\n",
            "\n",
            "SVM\n",
            "Precision: 0.774559686888454\n",
            "Recall: 0.7908091908091908\n",
            "F1 Score: 0.7800709143784266\n",
            "\n",
            "LSTM\n",
            "Precision: 0.7274371859296482\n",
            "Recall: 0.7230769230769231\n",
            "F1 Score: 0.7257989031956127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFa2BdRN7iql"
      },
      "source": [
        "I think SVM does the best compared to all the other models. Although its Precision score is not the best which doesnt make it the best model to predict labels accurately, the recall score brings the whole score up for SVM meaning using this model we will make less mistakes compared to other models.\n",
        "\n",
        "To improve performance we can remove the max_iter parameter in SVC and max_depth in Random Forest allowing the models to converge even further to get more accurate results. Also throwing more data at the model will increase the accuracy. Reading the documentation for the data tells us that it is auto labeled considering emoticons to determine the polarity. A data which is hand labelled might fare better as there is a lot more to the polarity of a text than the emoticons used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhcr9RO5qqMT"
      },
      "source": [
        "5. Add to the comparison of #4 a the manually calculated precision, recall and F1 score\n",
        "using VADER and their suggested defaults to categorize the test split tweets in positive\n",
        "or negative. Answer the following questions: Is this approach as good as the previous\n",
        "ones? Why do you think this is? (30 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju1PPHriqsEZ",
        "outputId": "0afd2c26-307b-423b-f532-d3aa23c8ed3b"
      },
      "source": [
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
        "sia = SIA()\n",
        "vader_labels = []\n",
        "for text in x_test.text.values:\n",
        "  sentiment_scores = (sia.polarity_scores(text))\n",
        "  if sentiment_scores['compound']>0:\n",
        "    vader_labels.append(4)\n",
        "  else:\n",
        "    vader_labels.append(0)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(y_test, vader_labels)\n",
        "print(\"\\nVader\")\n",
        "Precision1 = mat[0][0] / (mat[0][0] + mat[0][1])\n",
        "print(\"Precision: \", str(Precision1))\n",
        "Recall1 = mat[0][0] / (mat[0][0] + mat[1][0])\n",
        "print(\"Recall: \",str(Recall1))\n",
        "F_Measure1 = (2 * Precision1 * Recall1) / (Precision1 + Recall1)\n",
        "print(\"F Measure: \",str(F_Measure1))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "\n",
            "Vader\n",
            "Precision:  0.6856856856856857\n",
            "Recall:  0.6419868791002812\n",
            "F Measure:  0.6631171345595354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAcjDELZ9IK9"
      },
      "source": [
        "Vader is a general pupose tool trained on social media text which makes use of lexical features (mainly words). Our dataset is auto labelled based on emoticons and not words. This might be the reason why vader did not perform as well as other models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKM5WoQv9-fW"
      },
      "source": [
        "Bonus (30 points): Try the following things to improve the LSTM model:\n",
        "\n",
        "1) Use 90% training data, 10% testing\n",
        "\n",
        "2) Remove stopwords from the tweets.\n",
        "\n",
        "3) Remove all user mentions for the tweets (@something)\n",
        "\n",
        "Compare all three new models in terms of their precision, recall and F1 score. Answer the\n",
        "following questions: Did this change the results in any way? Why do you think so?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgRoAnHIKWCe",
        "outputId": "04dd5774-c8b9-425b-f52c-4f4ac9cf9bef"
      },
      "source": [
        "print(training_data)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         polarity  ...                                               text\n",
            "1062755         4  ...  @writesfortea  Always happy to share the aweso...\n",
            "436476          0  ...  Okay yay it's Sunday! Not  must feed my addict...\n",
            "974124          4  ...  @jasons wow, I just saw this @ thingie, sorry ...\n",
            "172330          0  ...  @monkeymoosh Happened to me the other day.  Wa...\n",
            "548362          0  ...  my ears went up like a startled Dog's when i f...\n",
            "...           ...  ...                                                ...\n",
            "538585          0  ...  @RegularOlTy so pissed Ty. SO pissed. Dude, I ...\n",
            "1522938         4  ...  @MissShimry  Maybe if you chill out it may go ...\n",
            "1141533         4  ...  Trying to go to sleep before 8:30 for 6AM ride...\n",
            "363651          0  ...       not the best way to start off summer, SICK. \n",
            "1285218         4  ...  Wax On. Wax Off .FIGHT! hehehe  http://punchmo...\n",
            "\n",
            "[50000 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLkmCcQG-EUe"
      },
      "source": [
        "from nltk.corpus import stopwords  \n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "np.random.seed(2361)\n",
        "\n",
        "traindata = {}\n",
        "s_words = stopwords.words('english')\n",
        "traindata['tweet_without_stopwords'] = training_data.text.apply(lambda x: ' '.join([word for word in x.split() if word not in (s_words)]))\n",
        "tknzr = TweetTokenizer(strip_handles=True)\n",
        "result = tknzr.tokenize(str(training_data.text))\n",
        "traindata['tweet_without_usermention'] = traindata['tweet_without_stopwords'].apply(lambda x: ' '.join(tknzr.tokenize(x)))\n",
        "x_train, x_test, y_train, y_test = train_test_split(traindata['tweet_without_usermention'], training_data.polarity,train_size=0.90)\n",
        "y_train = y_train.to_frame()\n",
        "y_test = y_test.to_frame()\n",
        "\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc5E0osgIw7x"
      },
      "source": [
        "np.random.seed(2361)\n",
        "model_nb = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "model_nb.fit(x_train.values.ravel(), y_train.polarity.ravel())\n",
        "labels2 = model_nb.predict(x_test.values)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2diMfo4I15T"
      },
      "source": [
        "np.random.seed(2361)\n",
        "y_train_values = y_train.polarity.ravel()\n",
        "y_train_values = y_train_values.astype(np.int8)\n",
        "model_rf = make_pipeline(TfidfVectorizer(), RandomForestClassifier(n_jobs=-1,warm_start=True,max_depth=1000))\n",
        "model_rf.fit(x_train.values.ravel(), y_train_values)\n",
        "labels3 = model_rf.predict(x_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_14ufTwI4ZN",
        "outputId": "e34fb9fa-9825-49cc-d8d0-1cb4bffe3439"
      },
      "source": [
        "np.random.seed(2361)\n",
        "model_svm = make_pipeline(TfidfVectorizer(), SVC(max_iter=20000))\n",
        "model_svm.fit(x_train.values.ravel(), y_train_values)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=20000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidfvectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('svc',\n",
              "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                     gamma='scale', kernel='rbf', max_iter=20000,\n",
              "                     probability=False, random_state=None, shrinking=True,\n",
              "                     tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC4FcTSyI7_M"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=280)\n",
        "tokenizer.fit_on_texts(training_data.text.values) \n",
        "sequences_train = tokenizer.texts_to_sequences(x_train.values)\n",
        "sequences_test = tokenizer.texts_to_sequences(x_test.values)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwjqP2C1I_8h",
        "outputId": "c59b1721-08e1-49f4-ba30-100ee9ebffb2"
      },
      "source": [
        "!pip install numpy==1.16.2\n",
        "\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from numpy import array\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "review_length = 280\n",
        "vocab_size = 10000\n",
        "x1_train = sequence.pad_sequences(sequences_train, maxlen = review_length)\n",
        "x1_test = sequence.pad_sequences(sequences_test, maxlen = review_length)\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim = vocab_size, \n",
        "        output_dim = 32, \n",
        "        input_length = review_length \n",
        "    )\n",
        ")\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 \n",
        "    )\n",
        ")\n",
        "model.add(\n",
        "    tf.keras.layers.LSTM(\n",
        "        units=32 \n",
        "    )\n",
        ")\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 \n",
        "    )\n",
        ")\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1,\n",
        "        activation='sigmoid'\n",
        "    )\n",
        ")\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy, \n",
        "    optimizer=tf.keras.optimizers.Adam(), \n",
        "    metrics=['accuracy']) \n",
        "model.summary()\n",
        "y_train1 = y_train\n",
        "y_test1 = y_test\n",
        "y_train1 = y_train1.replace(4,1)\n",
        "y_test1 = y_test1.replace(4,1)\n",
        "history = model.fit(x1_train, y_train1,batch_size=256,epochs=3,validation_split=0.2,verbose=1)\n",
        "\n",
        "predicted_classes = model.predict_classes(x1_test)\n",
        "print(predicted_classes)\n",
        "classification_report = classification_report(y_test1, predicted_classes)\n",
        "print(classification_report)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.16.2 in /usr/local/lib/python3.7/dist-packages (1.16.2)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 280, 32)           320000    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 280, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 328,353\n",
            "Trainable params: 328,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "141/141 [==============================] - 5s 24ms/step - loss: 0.6751 - accuracy: 0.5820 - val_loss: 0.5850 - val_accuracy: 0.6847\n",
            "Epoch 2/3\n",
            "141/141 [==============================] - 3s 21ms/step - loss: 0.5858 - accuracy: 0.6825 - val_loss: 0.5813 - val_accuracy: 0.6880\n",
            "Epoch 3/3\n",
            "141/141 [==============================] - 3s 21ms/step - loss: 0.5816 - accuracy: 0.6813 - val_loss: 0.5788 - val_accuracy: 0.6900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[1]\n",
            " [0]\n",
            " [1]\n",
            " ...\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.65      0.68      2471\n",
            "           1       0.69      0.74      0.71      2529\n",
            "\n",
            "    accuracy                           0.70      5000\n",
            "   macro avg       0.70      0.70      0.70      5000\n",
            "weighted avg       0.70      0.70      0.70      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozv81bgIJDPg",
        "outputId": "582ee6cf-bc8a-44f6-8de5-62b3cd2bbb41"
      },
      "source": [
        "import sklearn\n",
        "\n",
        "Precision = []\n",
        "Recall = []\n",
        "F1Score = []\n",
        "\n",
        "labels_nb = model_nb.predict(x_test.values)\n",
        "\n",
        "Precision.append(sklearn.metrics.precision_score(y_test.values,labels_nb,pos_label=4))\n",
        "Recall.append(sklearn.metrics.recall_score(y_test,labels_nb,pos_label=4))\n",
        "F1Score.append( sklearn.metrics.f1_score(y_test,labels_nb, average='macro',pos_label=4))\n",
        "\n",
        "\n",
        "labels_rf = model_rf.predict(x_test.values)\n",
        "Precision.append(sklearn.metrics.precision_score(y_test,labels_rf,pos_label=4))\n",
        "Recall.append(sklearn.metrics.recall_score(y_test,labels_rf,pos_label=4))\n",
        "F1Score.append( sklearn.metrics.f1_score(y_test,labels_rf, average='macro',pos_label=4))\n",
        "\n",
        "\n",
        "\n",
        "labels_svm = model_svm.predict(x_test.values)\n",
        "Precision.append(sklearn.metrics.precision_score(y_test,labels_svm,pos_label=4))\n",
        "Recall.append(sklearn.metrics.recall_score(y_test,labels_svm,pos_label=4))\n",
        "F1Score.append(sklearn.metrics.f1_score(y_test,labels_svm, average='macro',pos_label=4))\n",
        "\n",
        "\n",
        "Precision.append(sklearn.metrics.precision_score(y_test1,predicted_classes,pos_label=1))\n",
        "Recall.append(sklearn.metrics.recall_score(y_test1,predicted_classes,pos_label=1))\n",
        "F1Score.append(sklearn.metrics.f1_score(y_test1,predicted_classes, average='macro',pos_label=1))\n",
        "\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 4) is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 4) is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 4) is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZgL5pJXJFYm",
        "outputId": "606d0598-2c09-4201-df4e-30a3c6087180"
      },
      "source": [
        "print(\"Bayes\")\n",
        "\n",
        "print('Precision:', Precision[0])\n",
        "print('Recall:', Recall[0])\n",
        "print('F1 Score:',F1Score[0])\n",
        "\n",
        "print(\"\\nRandom Forest\")\n",
        "\n",
        "print('Precision:',Precision[1] )\n",
        "print('Recall:',Recall[1] )\n",
        "print('F1 Score:',F1Score[1] )\n",
        "\n",
        "print(\"\\nSVM\")\n",
        "\n",
        "print('Precision:',Precision[2] )\n",
        "print('Recall:',Recall[2] )\n",
        "print('F1 Score:',F1Score[2] )\n",
        "\n",
        "print(\"\\nLSTM\")\n",
        "\n",
        "print('Precision:',Precision[3] )\n",
        "print('Recall:',Recall[3] )\n",
        "print('F1 Score:',F1Score[3] )\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bayes\n",
            "Precision: 0.7616935483870968\n",
            "Recall: 0.7469355476472914\n",
            "F1 Score: 0.7537992023094156\n",
            "\n",
            "Random Forest\n",
            "Precision: 0.7461159530125048\n",
            "Recall: 0.77856860419138\n",
            "F1 Score: 0.7537219619461588\n",
            "\n",
            "SVM\n",
            "Precision: 0.7683114880493447\n",
            "Recall: 0.7880585211546066\n",
            "F1 Score: 0.7724623032874576\n",
            "\n",
            "LSTM\n",
            "Precision: 0.6874312935141077\n",
            "Recall: 0.741795175958877\n",
            "F1 Score: 0.6979958959527279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVNrYO11MXwd"
      },
      "source": [
        "This did not make any significant changes in the results. SVM is still the best one among them and LSTM model still underperforms. We removed stop words and tweet mentions but we didnt remove the emoticons on which this dataset is classified. Emoticons are the lexicons that define the polarity in this case making removing stopo words and mentions not make a difference. "
      ]
    }
  ]
}